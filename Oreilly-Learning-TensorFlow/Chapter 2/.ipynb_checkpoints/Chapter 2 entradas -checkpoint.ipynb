{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# practicar nodos y constantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En tensorflow primero se declaran constantes y variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tf.constant(5)\n",
    "b=tf.constant(2)\n",
    "c=tf.constant(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paso 2 se declaran operaciones *que tengan que ver con los grafos*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=tf.multiply(a,b)\n",
    "e=tf.add(c,b)\n",
    "f=tf.subtract(d,e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paso 3 se inicia sesion, en la sesion se llama ejecutar al ultimo grafo o nodo, este ejecutara el resto\n",
    "tambien aqui van operaciones paralelas a los grafos ej. funcion de costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sess=tf.Session()\n",
    "outs=sess.run(f)\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs=5\n"
     ]
    }
   ],
   "source": [
    "print(\"outs={}\".format(outs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construyendo y manejando Grafos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.framework.ops.Graph object at 0x000002C4F21ED390>\n",
      "<tensorflow.python.framework.ops.Graph object at 0x000002C4F2228160>\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tf.get_default_graph())\n",
    "g=tf.Graph()\n",
    "p=tf.constant(5)\n",
    "print(g)\n",
    "print(a.graph is g)\n",
    "print(a.graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with \n",
    "esta declaracion permite ejecutar y cerrar sesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.get_default_graph()\n",
    "g2 = tf.Graph()\n",
    "\n",
    "print(g1 is tf.get_default_graph())\n",
    "\n",
    "with g2.as_default():\n",
    "    print(g1 is tf.get_default_graph())\n",
    "    \n",
    "print(g1 is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetches\n",
    "Son el argumento (entrada ) de los grafos que queremos ejecutar, por ejemplo los pixeles de una imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs=[5, 2, 3, 10, 5, 5]\n",
      "<class 'numpy.int32'>\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    fetches=[a,b,c,d,e,f]\n",
    "    outs=sess.run(fetches)\n",
    "print('outs={}'.format(outs))\n",
    "print(type(outs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flowing Tensors\n",
    "cuando se declaran variables, constantes y operaciones estas no se ejecutan solo son una instancia, que se ejecutara hasta el inicio de sersion, es decir declaras la estructura, el flujo de datos que entra en la sesion es lo que la ejecuta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_4:0\", shape=(), dtype=float64)\n",
      "<dtype: 'float64'>\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant(4.0, dtype=tf.float64)\n",
    "print(c) # imprime nombre del nodo, dimensiones y tipo\n",
    "print(c.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_5:0\", shape=(), dtype=string)\n",
      "<dtype: 'string'>\n"
     ]
    }
   ],
   "source": [
    "v = tf.constant(\"4.0\", dtype=tf.string)\n",
    "print(v)\n",
    "print(v.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Casting\n",
    "Esto se refiere que hay que tener cuidado de que todos los datos que entran a un grafo sean del tipo correcto, si son de datos diferentes se pueden \"convertir\" usando al funcion cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "x=tf.constant([1,2,3],name='x',dtype=tf.float32)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'int64'>\n"
     ]
    }
   ],
   "source": [
    "x=tf.cast(x,tf.int64)\n",
    "print(x.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'string'>\n"
     ]
    }
   ],
   "source": [
    "x=tf.cast(x,tf.string)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor arrays y shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python list input: (2, 3)\n"
     ]
    }
   ],
   "source": [
    "c1=tf.constant([[1,2,3],[4,5,6]])\n",
    "print(\"Python list input: {}\".format(c1.get_shape()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D numpy array input:(2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "c2=tf.constant(np.array([[[1,2,3], \n",
    "                    [4,5,6]], \n",
    "                    [[1,1,1], \n",
    "                    [2,2,2]]]))\n",
    "print('3D numpy array input:{}'.format(c2.get_shape()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the content of c: \n",
      " [ 0.  1.  2.  3.  4.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "c3=tf.linspace(0.0,4.0,5)\n",
    "print('the content of c: \\n {} \\n'.format(c3.eval()))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "tf.InteractiveSession() permite reemplazar tf.Session()  sin la necesidad de asignar la sesion a alguna variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:0\n",
      "c_1:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    c1 = tf.constant(4, dtype=tf.float64, name = \"c\")\n",
    "    c2 = tf.constant(4, dtype=tf.int32, name = \"c\")\n",
    "    \n",
    "print(c1.name)\n",
    "print(c2.name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo nodo tiene un nombre, que no tiene nada que ver con el nombre de la variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scopes\n",
    " son herramientas para crear grupos de nodos, creo que es para herramientas de debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:0\n",
      "prefix_name/c:0\n",
      "prefix_name/c_1:0\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    c1 = tf.constant(4, dtype=tf.float64, name = \"c\")\n",
    "    with tf.name_scope(\"prefix_name\"):\n",
    "        c2 = tf.constant(4, dtype=tf.int32, name = \"c\")\n",
    "        c3 = tf.constant(4, dtype=tf.float64, name = \"c\")\n",
    "    \n",
    "    print(c1.name)\n",
    "    print(c2.name)\n",
    "    print(c3.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Variables, Placeholders, and Simple Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre run: \n",
      "\n",
      "\n",
      "post run: \n",
      "[[-0.15214291  0.01085112  0.78268039  0.73250645  0.19686136]]\n"
     ]
    }
   ],
   "source": [
    "init_val = tf.random_normal((1,5),0,1)\n",
    "var = tf.Variable(init_val, name='var')\n",
    "print(\"pre run: \\n\".format(var))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    post_var = sess.run(var)\n",
    "    \n",
    "print(\"\\npost run: \\n{}\".format(post_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables son elementos de entrada al grafo pueden ser fijas o cambiar dentro de la sesion, pueden inicializarse de manera independiente, manual o automaticamente con la funcion tf.globlas_variables_initilizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholders\n",
    "esto son la entrada de las variables al grafo, esto son las variables que entraran al grafo en la seccion Session.run(), por ejemplo uno lo declara como las entradas a nuestra red X o como las etiquetas Y es decir son la entrada al flujo de informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph = tf.placeholder(tf.float32, shape=(None, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "los placeholder, se tiene que declarar su tipo de dato, y sus dimensiones, si queremos que sean de tamaño indefinido solo basta colocar como de tamaño None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess.run(s, feed_dict={x: X_data, w: w_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para alimentar el flujo de datos en la session la entrada del placeholder atraves de diccionarios \"feed_dict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs = 0.934952974319458\n"
     ]
    }
   ],
   "source": [
    "x_data = np.random.randn(5,10)\n",
    "w_data = np.random.randn(10,1)\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=(5,10))\n",
    "    w = tf.placeholder(tf.float32, shape=(10,1))\n",
    "    b = tf.fill((5,1),-1.)\n",
    "    xw = tf.matmul(x,w)\n",
    "    xwb = xw + b\n",
    "    s = tf.reduce_max(xwb)\n",
    "    with tf.Session() as sess:\n",
    "        outs = sess.run(s,feed_dict={x: x_data, w: w_data})\n",
    "        \n",
    "print(\"outs = {}\".format(outs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en el codigo anterior se generan datos aleatorios (un arreglo) se asigna a los placeholders del grafo \"s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "Optimizacion es importante, para el hot encoding es decir la distancia mas corta entre la prediccion y el valor \"real\" (mas adelante esta definicion se llamara funcion de perdida \"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ## Regresion\n",
    "    este es el primer paso hacia una red neuronal (Falta la funcion de activacion como elemento basico de una neurona) \n",
    "    la regresion esta definida como :\n",
    "    z=WX+b\n",
    "    donde :\n",
    "    W: son los pesos \n",
    "    X: es la entrada de nuestro sistema\n",
    "    b: es un offset llamado bias.\n",
    "    \n",
    "    Lo que tenemos que optimizar es:\n",
    "    Y=z+epsilon\n",
    "    donde:\n",
    "    Y: es la clase o etiqueta correcta\n",
    "    z: es nuestra prediccion\n",
    "    epsilon: es ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "y_true = tf.placeholder(tf.float32, shape=None)\n",
    "w = tf.Variable([[0,0,0]], dtype=tf.float32,name=\"weights\")\n",
    "b = tf.Variable(0,dtype=tf.float32,name=\"bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero declaramos los placeholders las entradas de datos a nuestro grafo (x entrada, y_true: etiquetas) y declaramos las variables que tenedremo que optimizar que son los pesos y bias (w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =tf.matmul(w,tf.transpose(x)) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nuestra funcion de prediccion, en la multiplicacion hicimos una transpuesta porque que la operacion multiplicacion tuviera las correctas dimensiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcion de perdida (loss function)\n",
    "es la discrepancia entre nuestra prediccion y lo observado (etiqueta) buscamos que este funcion sea de orden muy pequeño segun el Dr. Andrew Ng en el orden 10-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE\n",
    "Mean Square Error (Error cuadratico medio) mide el promedio de los errores al cuadrado osea la diferencia entre el estimador o lo que se estima (varianza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss = tf.reduce_mean(tf.square(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aunque este en python si la operacion matematica se usa dentro de tensorflow las operaciones son con tensorflow, esto tambien permite que se ejecuten en el GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Entropy\n",
    "mide la similiridad entre dos distribuciones (entre la prediccion y su clase), se usa esta tecnica principalmente despues de ejecutar la red. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "\n",
    "#loss = tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usa logits se llama asi a la distribucion, como son dos distribuciones la de la etiqueta y la dela prediccion mide la diferencia entre ellas (tenemos que optimizar para que la distancia sea la minima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD\n",
    "Es la principal tecnica de optimizacion usada en deep learning sus siglas son Stochastic Gradiente Descent ( gradiente descendiente estocastico) esta tecnica consiste e ir haciendo pequeñas derivadas para encontrar los pesos y bias que optimicen la funcion de perdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "#train = optimizer.minimize(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pequeña aplicacion MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=np.random.randn(2000,3) # esto creamos datos de manera aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_real = [0.3,0.5,0.1]\n",
    "b_real = -0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.randn(1,2000)*0.1\n",
    "y_data = np.matmul(w_real, x_data.T) + b_real + noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_STEPS = 10\n",
    "\n",
    "g = tf.Graph()\n",
    "wb_ = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [array([[ 0.29071742,  0.47462577,  0.11976184]], dtype=float32), -0.18375403]\n",
      "5 [array([[ 0.29947051,  0.49832156,  0.10246882]], dtype=float32), -0.20102274]\n",
      "10 [array([[ 0.29947054,  0.49832159,  0.1024688 ]], dtype=float32), -0.20102274]\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=[None,3])\n",
    "    y_true = tf.placeholder(tf.float32,shape=None)\n",
    "   #y_pred = tf.matmul(w,tf.transpose(x)) + b\n",
    "    \n",
    "    with tf.name_scope('inference') as scope:\n",
    "        w = tf.Variable([[0,0,0]],dtype=tf.float32,name='weights')\n",
    "        b = tf.Variable(0,dtype=tf.float32,name='bias')\n",
    "        y_pred = tf.matmul(w,tf.transpose(x)) + b\n",
    "    with tf.name_scope('loss') as scope:\n",
    "        loss = tf.reduce_mean(tf.square(y_true-y_pred))\n",
    "    with tf.name_scope('train') as scope:\n",
    "        learning_rate = 0.5\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        train = optimizer.minimize(loss) \n",
    "        \n",
    "        \n",
    "    # Before starting, initialize the variables. We will 'run' this first.\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for step in range(NUM_STEPS):\n",
    "            sess.run(train,{x: x_data, y_true: y_data})\n",
    "            if (step % 5 == 0):\n",
    "                print(step, sess.run([w,b]))\n",
    "                wb_.append(sess.run([w,b]))\n",
    "        print(10, sess.run([w,b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20000\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "# === Create data and simulate results =====\n",
    "x_data = np.random.randn(N,3)\n",
    "w_real = [0.3,0.5,0.1]\n",
    "b_real = -0.2\n",
    "wxb = np.matmul(w_real,x_data.T) + b_real\n",
    "y_data_pre_noise = sigmoid(wxb)\n",
    "y_data = np.random.binomial(1,y_data_pre_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.sigmoid(y_pred)\n",
    "loss = y_true*tf.log(y_pred) - (1-y_true)*tf.log(1-y_pred)\n",
    "loss = tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32) is not an element of this graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\ledra\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1063\u001b[0m             subfeed_t = self.graph.as_graph_element(subfeed, allow_tensor=True,\n\u001b[1;32m-> 1064\u001b[1;33m                                                     allow_operation=False)\n\u001b[0m\u001b[0;32m   1065\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ledra\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3034\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3035\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3036\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ledra\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3113\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3114\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3115\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-eaf848a190e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUM_STEPS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ledra\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ledra\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1065\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m             raise TypeError('Cannot interpret feed_dict key as Tensor: '\n\u001b[1;32m-> 1067\u001b[1;33m                             + e.args[0])\n\u001b[0m\u001b[0;32m   1068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder:0\", shape=(?, 3), dtype=float32) is not an element of this graph."
     ]
    }
   ],
   "source": [
    "NUM_STEPS = 50\n",
    "with tf.name_scope('loss')as scope:\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true,logits=y_pred) \n",
    "    loss = tf.reduce_mean(loss)\n",
    "# Before starting, initialize the variables.  We will 'run' this first.\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session()as sess:\n",
    "    sess.run(init)      \n",
    "    for step in range(NUM_STEPS):\n",
    "        sess.run(train,{x: x_data, y_true: y_data})\n",
    "        if(step % 5 == 0):\n",
    "            print(step, sess.run([w,b]))\n",
    "            wb_.append(sess.run([w,b]))\n",
    "    print(50, sess.run([w,b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
