{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "mnist = input_data.read_data_sets(os.path.join('.', 'mnist'), one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=mnist.train.images\n",
    "X_test=mnist.test.images\n",
    "Y_train=mnist.train.labels\n",
    "Y_test=mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outputs=10\n",
    "num_inputs=784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x,num_inputs,num_outputs,num_layers,num_neurons):\n",
    "    w=[]\n",
    "    b=[]\n",
    "    for i in range(num_layers):\n",
    "        #weights\n",
    "        w.append(tf.Variable(tf.random_normal([num_inputs if i==0 else num_neurons[i-1],num_neurons[i]]),name='w_{0:04d}'.format(i)))\n",
    "        #biases\n",
    "        b.append(tf.Variable(tf.random_normal([num_neurons[i]]),name='b_{0:04d}'.format(i)))\n",
    "        \n",
    "    #weights last layer\n",
    "    w.append(tf.Variable(tf.random_normal([num_neurons[num_layers-1] if num_layers>0 else num_inputs,num_outputs]),name='w_out'))\n",
    "    #biases last layer\n",
    "    b.append(tf.Variable(tf.random_normal([num_outputs]),name='b_out'))\n",
    "        \n",
    "    #X is input layer\n",
    "    layer=x\n",
    "    #hidden layers\n",
    "    for i in range(num_layers):\n",
    "        layer=tf.nn.relu(tf.matmul(layer,w[i])+b[i])\n",
    "    #add output layer\n",
    "    layer=tf.matmul(layer,w[num_layers]+b[num_layers])\n",
    "    \n",
    "    return layer\n",
    "            \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_batch_func(batch_size=100):\n",
    "    X_batch, Y_batch=mnist.train.next_batch(batch_size)\n",
    "    return [X_batch,Y_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorflow_classification(n_epochs, n_batches, batch_size, model, optimizer, loss, accuracy_function, X_test, Y_test):\n",
    "    with tf.Session() as tfs:\n",
    "        tfs.run(tf.global_variables_initializer())\n",
    "        for epoch in range(n_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for batch in range(n_batches):\n",
    "                X_batch, Y_batch = mnist_batch_func(batch_size)\n",
    "                feed_dict = {x: X_batch, y: Y_batch}\n",
    "                _, batch_loss = tfs.run([optimizer, loss], feed_dict)\n",
    "                epoch_loss += batch_loss\n",
    "            average_loss = epoch_loss / n_batches\n",
    "            print(\"epoch: {0:04d} loss = {1:0.6f}\".format(epoch, average_loss))\n",
    "        feed_dict = {x: X_test, y: Y_test}\n",
    "        accuracy_score = tfs.run(accuracy_function, feed_dict=feed_dict)\n",
    "        print(\"accuracy={0:.8f}\".format(accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input images\n",
    "x = tf.placeholder(dtype=tf.float32, name=\"x\",shape=[None, num_inputs]) \n",
    "# target output\n",
    "y = tf.placeholder(dtype=tf.float32, name=\"y\",shape=[None, num_outputs])\n",
    "num_layers = 0\n",
    "num_neurons = []\n",
    "learning_rate = 0.01\n",
    "n_epochs = 50\n",
    "batch_size = 100\n",
    "n_batches = int(mnist.train.num_examples/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp(x=x,num_inputs=num_inputs,num_outputs=num_outputs,num_layers=num_layers,num_neurons=num_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-cdad1bafbb6b>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "predictions_check = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
    "accuracy_function = tf.reduce_mean(tf.cast(predictions_check, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0000 loss = 16.855408\n",
      "epoch: 0001 loss = 11.238250\n",
      "epoch: 0002 loss = 6.905455\n",
      "epoch: 0003 loss = 4.968870\n",
      "epoch: 0004 loss = 3.680636\n",
      "epoch: 0005 loss = 3.134603\n",
      "epoch: 0006 loss = 2.705464\n",
      "epoch: 0007 loss = 2.428341\n",
      "epoch: 0008 loss = 2.258404\n",
      "epoch: 0009 loss = 2.067581\n",
      "epoch: 0010 loss = 1.960110\n",
      "epoch: 0011 loss = 1.751432\n",
      "epoch: 0012 loss = 1.703946\n",
      "epoch: 0013 loss = 1.697652\n",
      "epoch: 0014 loss = 1.584392\n",
      "epoch: 0015 loss = 1.536169\n",
      "epoch: 0016 loss = 1.464997\n",
      "epoch: 0017 loss = 1.471054\n",
      "epoch: 0018 loss = 1.432210\n",
      "epoch: 0019 loss = 1.417249\n",
      "epoch: 0020 loss = 1.359397\n",
      "epoch: 0021 loss = 1.331323\n",
      "epoch: 0022 loss = 1.261358\n",
      "epoch: 0023 loss = 1.303885\n",
      "epoch: 0024 loss = 1.260155\n",
      "epoch: 0025 loss = 1.249626\n",
      "epoch: 0026 loss = 1.229917\n",
      "epoch: 0027 loss = 1.197596\n",
      "epoch: 0028 loss = 1.156248\n",
      "epoch: 0029 loss = 1.177517\n",
      "epoch: 0030 loss = 1.170925\n",
      "epoch: 0031 loss = 1.088233\n",
      "epoch: 0032 loss = 1.159092\n",
      "epoch: 0033 loss = 1.131563\n",
      "epoch: 0034 loss = 1.138070\n",
      "epoch: 0035 loss = 1.119371\n",
      "epoch: 0036 loss = 1.084947\n",
      "epoch: 0037 loss = 1.071797\n",
      "epoch: 0038 loss = 1.060020\n",
      "epoch: 0039 loss = 1.042035\n",
      "epoch: 0040 loss = 1.035698\n",
      "epoch: 0041 loss = 1.024601\n",
      "epoch: 0042 loss = 1.007874\n",
      "epoch: 0043 loss = 1.007785\n",
      "epoch: 0044 loss = 1.019702\n",
      "epoch: 0045 loss = 0.998567\n",
      "epoch: 0046 loss = 0.963765\n",
      "epoch: 0047 loss = 0.997126\n",
      "epoch: 0048 loss = 0.969746\n",
      "epoch: 0049 loss = 0.954206\n",
      "accuracy=0.86250001\n"
     ]
    }
   ],
   "source": [
    "tensorflow_classification(n_epochs, n_batches, batch_size, model, optimizer, loss, accuracy_function, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
